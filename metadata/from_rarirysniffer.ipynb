{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@date: 11/01/2022\n",
    "\"\"\"\n",
    "CONTRACT_ADDRESS = \"0x65b28ed75c12d8ce29d892de9f8304a6d2e176a7\"\n",
    "\n",
    "SAVE_RAW_DATA = False # Set to True to keep each token raw json\n",
    "COMPRESS_RAW_DATA = False # Set to True to zip all raw json to save disk space\n",
    "\n",
    "# Collection name will be collected from raritysniffer response\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "dt_now = datetime.datetime.utcnow()\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Working in directory: {os.getcwd()}\")\n",
    "\n",
    "url = \"https://v2.raritysniffer.com/api/index.php?query=fetch&collection=\" + CONTRACT_ADDRESS + \"&taskId=any&norm=true&partial=false&traitCount=true\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36\",\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "response_data = response.json()\n",
    "\n",
    "# list to make completeness checks\n",
    "token_ids = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    raw_metadata = [] # Initiate list of dicts that will be converted to DataFrame\n",
    "    COLLECTION_NAME = response_data['name'].replace(\" \", \"\")\n",
    "    print(f\"Received data for {COLLECTION_NAME}\")\n",
    "    print(f\"{len(response_data['data'])} tokens in the collection\")\n",
    "\n",
    "    # Create folder to store metadata\n",
    "    if SAVE_RAW_DATA:\n",
    "        folder = f'../metadata/raw_attributes/{COLLECTION_NAME}/'\n",
    "        print(f\"Saving metadata to {folder}\")\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "    for i, token in enumerate(response_data['data']):\n",
    "        token_ids.append(token['id'])\n",
    "        # Add token name and token URI traits to the trait dictionary\n",
    "        traits = dict()\n",
    "        traits['TOKEN_ID'] = token['id']\n",
    "        traits['TOKEN_NAME'] = token['name']\n",
    "\n",
    "        #token['attributes'] = token.pop('traits')\n",
    "        for atr in token['traits']:\n",
    "            if not atr['c'] == 'Trait Count':\n",
    "                traits[atr['c']] = atr['n']\n",
    "\n",
    "        # add this token to dictionary list\n",
    "        raw_metadata.append(traits)\n",
    "        \n",
    "        if SAVE_RAW_DATA:\n",
    "            print(f\"Saving raw attributes to disk...\")\n",
    "            PATH = f\"../metadata/raw_attributes/{COLLECTION_NAME}/{token['id']}.json\"\n",
    "            with open(PATH, \"w\") as destination_file:\n",
    "                json.dump(token, destination_file)\n",
    "else:\n",
    "    print(f\"Got a {response.status_code} error from raritysniffer api\")\n",
    "    print(\"Exiting\")\n",
    "\n",
    "print(f\"tokens in the list {len(token_ids)}\")\n",
    "print(f\"lower_id: {min(token_ids)}\")\n",
    "print(f\"upper_id: {max(token_ids)}\")\n",
    "\n",
    "if min(token_ids) == 0:\n",
    "    max_supply = max(token_ids) + 1\n",
    "    print(f\"max supply: {max(token_ids) + 1}\")\n",
    "else:\n",
    "    max_supply = max(token_ids)\n",
    "    print(f\"max supply: {max(token_ids)}\")\n",
    "\n",
    "# warn if raritysniffer doesn't have the full collection\n",
    "# TODO: print a list of missing token ids\n",
    "if len(token_ids) != max_supply:\n",
    "    print(f\"{max_supply - len(token_ids)} tokens with missing metadata\")\n",
    "\n",
    "# Generate traits DataFrame and save to disk as csv\n",
    "trait_db = pd.DataFrame.from_records(raw_metadata)\n",
    "trait_db = trait_db.set_index(\"TOKEN_ID\")\n",
    "trait_db = trait_db.sort_index()\n",
    "print(trait_db.head())\n",
    "trait_db.to_csv(f\"raw_attributes/{COLLECTION_NAME}.csv\")\n",
    "\n",
    "# Calculate rarity_data csv with rarity.py\n",
    "print(f\"Calculating rarity data with 'rarity.py' using the command: python3 rarity.py -collection {COLLECTION_NAME}\")\n",
    "os.system(f\"python3 rarity.py -collection {COLLECTION_NAME}\")\n",
    "\n",
    "# Compress raw data and delete folder\n",
    "if COMPRESS_RAW_DATA:\n",
    "    print(\"Compressing raw metadata\")\n",
    "    dir_name = os.path.join(os.getcwd(), \"raw_attributes\", COLLECTION_NAME)\n",
    "    shutil.make_archive(dir_name, 'zip', dir_name)\n",
    "    shutil.rmtree(dir_name)\n",
    "\n",
    "print(\"--- %s seconds to process collection\" % (round(time.time() - start_time, 1)))\n",
    "print(\"finished.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
